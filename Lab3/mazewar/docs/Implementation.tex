\section{Implementation}\label{Impl}

This section presents the implementation of design proposed in section \ref{Design}.

\subsection{Component Implementation}\label{ImplComponent}

\paragraph*{Naming Service}

Similar to the server component implemented in lab 2, the naming service will create a socket that is embedded on the client code. The naming service will be created first and start listening on this socket, and when a new client is created, they will attempt to establish a connection at this socket first.

The naming service will spawn a new thread on client connection. The thread will simply put the new client name, and socket address into its local hash map, and reply the up-to-date hash map to the client, after which, the socket will be closed, and properly cleaned up.

While the naming service does form a central point of failure, its processing load is orders of magnitude lower than other component of the game, allowing it to scale up when number of players grows.

\paragraph*{Client Broadcaster}

Opposite to lab 2 server, the broadcast component will be a thread on the client side, constantly broadcasting every local action to every player registered to the hash map locally kept, which was obtained from naming service when the player first joined.

\paragraph*{Client Listener}

The listener on the client will be a series of threads each listening on an input stream to one of the currently connected players. 

\paragraph*{Client Holdback Queue}

This queue will be a priority queue that will automatically sort the packet inside with priority of sequence number decided with algorithm specified in \ref{ImplConsistency}.

\subsection{Consistency Implementation}\label{ImplConsistency}

As described in the book Distributed Systems Concepts and Design, there are two methods of implementing total ordering, a sequencer, and the ISIS method. Since sequencer requires a centralized component that needs to broadcast a global sequence number, this is equivalent to lab 2. The second method was the ISIS method described below.

\begin{enumerate}
\item Client p broadcasts $<$m,i$>$  with message m and unique id i to everyone.
 
\item On receiving m for the first time, m is added to the Holdback queue which is a priority queue and tagged as holdback. Reply to sender with a proposed priority, i.e. a sequence number, seq-number = 1 + largest-seq-number-heard-so-far, suffixed with the recipientâ€™s process ID to break tie. Note that the priority queue is always sorted by priority.

\item Client p collects all responses from the recipients, calculates their maximum, and re-broadcast original message with a final priority for m. 

\item On receiving m (with final priority), the receiver marks the message as OK, reorder the priority queue, and deliver the set of lowest priority messages that are marked as deliverable.
\end{enumerate}

During lecture a third method was discussed using Lamport clock, acknowledgement and a holdback queue. The section below describes this implementation and why it was chosen for this design.

\begin{enumerate}
\item Client p broadcasts  $<$m,l$>$  with message m and local Lamport clock number.
 
\item On receiving m for the first time, m is added to the Holdback queue which is a priority queue and tagged as holdback. Reply to sender with an acknowledgement with the up-to-date Lamport clock.

\item Client p collects all responses from the recipients, and plays the message from the front of the holdback queue when all the acknowledgements from all peers are received.
\end{enumerate}

This method is selected because it guarantees total system ordering as well as decentralized component, while being simpler in implementation than the ISIS method presented earlier.
